import os
import requests
import jieba
from dotenv import load_dotenv
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from db_init import get_db_url

# 1. ç¯å¢ƒé…ç½®
load_dotenv()
GUIJI_API_KEY = os.getenv("GUIJI_API_KEY")
GUIJI_EMB_URL = os.getenv("GUIJI_EMB_URL", "https://api.siliconflow.cn/v1/embeddings")
GUIJI_EMB_MODEL = os.getenv("GUIJI_EMB_MODEL", "BAAI/bge-m3")

engine = create_engine(get_db_url())
Session = sessionmaker(bind=engine)

# æ‰©å±•åœç”¨è¯åº“
STOPWORDS_PATH = "stopwords.txt"
EXTENDED_STOP_WORDS = {"ä¸€é¦–æ­Œ", "çš„ä¸€é¦–", "ä¸€ç§", "çš„ä¸€", "å¯¹äº", "å…³äº", "æˆ‘æƒ³", "å¬å¬", "çš„", "äº†", "åœ¨", "ï¼Œ", "ã€‚", "ï¼", "ï¼Ÿ", " ", "â€", "â€œ", "æ­Œ"}
if os.path.exists(STOPWORDS_PATH):
    with open(STOPWORDS_PATH, "r", encoding="utf-8") as f:
        for line in f:
            EXTENDED_STOP_WORDS.add(line.strip())

# ç»ˆæè„±æ°´è¯åº“ (ä¸¥ç¦è¿›å…¥è¯­ä¹‰åˆ†æ)
ULTRA_STOP_WORDS = {
    "æƒ³å¬", "ç»™æˆ‘", "æ¨è", "ä¸€é¦–", "æœ‰äº›", "å¬å¬", "æœ‰å…³", "å…³äº", "é‚£äº›", "çš„", "äº†", "åœ¨", "æˆ‘", "ä½ ", "ä»–", "å¥¹", "ï¼Œ", "ã€‚", "ï¼", "ï¼Ÿ", " ", "â€", "â€œ", "æ­Œ", "é€‚åˆ", "é‚£ç§", "ä¸€ç§"
}

def ultra_clean_query(query):
    """åªä¿ç•™æœ€å…·æ„å¢ƒçš„å®è¯"""
    words = jieba.lcut(query)
    # å½»åº•æ’é™¤å•å­—ï¼ˆé™¤äº†ç‰¹å®šçš„å¦‚'é›¨'ã€'æ„'è¿™ç§ï¼‰ï¼Œæ’é™¤è¶…å¼ºåœç”¨è¯
    cleaned = [w for w in words if w not in ULTRA_STOP_WORDS and len(w.strip()) > 1]
    # å¦‚æœå…¨è¢«è¿‡æ»¤äº†ï¼Œä¿åº•è¿”å›åŸè¯
    return cleaned if cleaned else words

def get_embedding(text_input):
    """è°ƒç”¨ API è·å–æŸ¥è¯¢è¯çš„å‘é‡"""
    headers = {"Authorization": f"Bearer {GUIJI_API_KEY}", "Content-Type": "application/json"}
    payload = {"model": GUIJI_EMB_MODEL, "input": text_input, "encoding_format": "float"}
    resp = requests.post(GUIJI_EMB_URL, headers=headers, json=payload, timeout=10)
    return resp.json()['data'][0]['embedding']

def deep_clean_query(query):
    """æå…¶æ¿€è¿›çš„æŸ¥è¯¢è¯å‡€åŒ–"""
    words = jieba.lcut(query)
    # è¿‡æ»¤æ‰åœç”¨è¯ï¼Œä¸”åªè¦é•¿åº¦å¤§äº1çš„å®è¯ï¼Œé™¤éæ˜¯ç‰¹å®šçš„æ­Œæ‰‹å/æ­Œå
    cleaned = [w for w in words if w not in EXTENDED_STOP_WORDS and len(w.strip()) > 0]
    return cleaned if cleaned else words

def hybrid_search(user_query, top_k=5):
    print(f"\nğŸš€ æ­£åœ¨è¿›è¡Œ 5.0 æè‡´è¯­å¢ƒæ£€ç´¢...")
    
    # --- 1. æ·±åº¦æ‹†è§£ ---
    cleaned_words = ultra_clean_query(user_query)
    print(f"  ğŸ” æå–æ ¸å¿ƒæ„å¢ƒè¯: {cleaned_words}")
    
    # ç­–ç•¥ï¼šè¯†åˆ«è„±æ°´åçš„ç¬¬ä¸€ä¸ªè¯æ˜¯å¦ä¸ºæ­Œæ‰‹/æ­Œåå…³é”®è¯
    artist_key = cleaned_words[0] if cleaned_words else ""
    # çº¯åŒ–æ„å¢ƒ Queryï¼šæŠŠæŸ¥è¯¢è¯é‡Œæ‰€æœ‰çš„åŠ¨ä½œå’Œæ­Œæ‰‹éƒ½åˆ æ‰ï¼Œåªç•™å‰©ä¸‹çš„æ„å‘
    vibe_words = [w for w in cleaned_words if w != artist_key]
    vibe_query = " ".join(vibe_words) if vibe_words else user_query
    
    # --- 2. çº¯å‡€å‘é‡åŒ– (åªæœæ„å¢ƒ) ---
    print(f"  ğŸ§  è¯­ä¹‰å¯¹é½ç›®æ ‡: \"{vibe_query}\"")
    query_vec = get_embedding(vibe_query)
    
    session = Session()
    try:
        # --- 3. æ··åˆ SQL 5.0 ---
        search_sql = text("""
            WITH scoring_pool AS (
                SELECT 
                    id, title, artist, vibe_tags, review_text,
                    (1 - (review_vector <=> CAST(:q_vec AS vector))) as semantic_score,
                    (
                      CASE WHEN artist ILIKE :artist_q THEN 4.0 ELSE 0 END + -- åŠ å¤§æ­Œæ‰‹æƒé‡åˆ° 4.0
                      CASE WHEN title = :title_exact THEN 2.0 ELSE 0 END + -- åªæœ‰å®Œå…¨ç›¸ç­‰æ‰ç»™æ ‡é¢˜åŠ åˆ†
                      ts_rank_cd(to_tsvector('simple', title || ' ' || segmented_lyrics), 
                               to_tsquery('simple', :ts_q))
                    ) as rational_score
                FROM songs
                WHERE review_vector IS NOT NULL
            )
            SELECT *,
                   (semantic_score * 0.4 + (CASE WHEN rational_score > 4 THEN 4 ELSE rational_score END / 4.0) * 0.6) as final_score
            FROM scoring_pool
            WHERE 
                (artist ILIKE :artist_q AND semantic_score > 0.4) -- åªè¦æäº†æ­Œæ‰‹åï¼Œå°±å¿…é¡»ä»ä»–çš„æ­Œé‡Œæ‰¾æœ€åƒçš„
                OR (:artist_q = '%%' AND semantic_score > 0.6)   -- æ²¡ææ­Œæ‰‹åï¼Œåˆ™å…¨åº“å¤§æœæ•
            ORDER BY final_score DESC
            LIMIT :limit
        """)
        
        ts_query = " | ".join(cleaned_words)

        results = session.execute(search_sql, {
            "q_vec": str(query_vec), 
            "ts_q": ts_query,
            "artist_q": f"%{artist_key}%" if artist_key else "%%",
            "title_exact": artist_key, # å°è¯•çœ‹ç¬¬ä¸€ä¸ªè¯æ˜¯ä¸æ˜¯æ ‡é¢˜
            "limit": top_k
        }).fetchall()
        
        print(f"\nğŸ¯ æ£€ç´¢ç»“æœ (è¯­ä¹‰çº¯åŒ– + æ­Œæ‰‹å¼ºç»‘å®š):")
        print("=" * 80)
        for i, row in enumerate(results):
            print(f"{i+1}. ã€{row.title}ã€‘ - {row.artist}")
            print(f"   ğŸ“Š æ·±åº¦åˆ†æ: è¯­ä¹‰({row.semantic_score:.3f}) | åŒ¹é…({row.rational_score:.3f})")
            print(f"   ğŸ“ AI è¯„è¯­: {row.review_text[:75]}...")
            print("-" * 80)
            
    finally:
        session.close()

if __name__ == "__main__":
    # ç¬¬ä¸€æ¬¡è¿è¡ŒåŠ è½½ä¸€ä¸‹ jieba å­—å…¸
    # print("æ­£åœ¨é¢„çƒ­åˆ†è¯å™¨...")
    # jieba.lcut("ä½ å¥½")
    
    while True:
        user_query = input("\nè¯·è¾“å…¥ä½ æƒ³å¬çš„å¿ƒæƒ…ã€åœºæ™¯æˆ–æ­Œè¯ç¢ç‰‡ (è¾“å…¥ q é€€å‡º): ")
        if user_query.lower() == 'q':
            break
        if not user_query.strip():
            continue
        try:
            hybrid_search(user_query)
        except Exception as e:
            print(f"âŒ æ£€ç´¢å¤±è´¥: {e}")
            # å¦‚æœæ˜¯ tsquery æŠ¥é”™ï¼Œé€šå¸¸æ˜¯å› ä¸ºç‰¹æ®Šå­—ç¬¦ï¼Œè¿™é‡Œç®€å•å¤„ç†ä¸‹
            if "syntax error" in str(e).lower():
                print("ğŸ’¡ æç¤ºï¼šè¯·å°è¯•è¾“å…¥æ›´ç®€å•çš„å…³é”®è¯ã€‚")
